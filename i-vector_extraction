{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8947614,"sourceType":"datasetVersion","datasetId":5384465},{"sourceId":8804326,"sourceType":"datasetVersion","datasetId":5295007}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"Hello world\")","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:08:40.512904Z","iopub.execute_input":"2024-09-18T07:08:40.513397Z","iopub.status.idle":"2024-09-18T07:08:40.522717Z","shell.execute_reply.started":"2024-09-18T07:08:40.513353Z","shell.execute_reply":"2024-09-18T07:08:40.521090Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Hello world\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA\nimport joblib\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:08:40.526590Z","iopub.execute_input":"2024-09-18T07:08:40.527346Z","iopub.status.idle":"2024-09-18T07:08:40.536888Z","shell.execute_reply.started":"2024-09-18T07:08:40.527284Z","shell.execute_reply":"2024-09-18T07:08:40.534666Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\n# Function to extract features from a single audio file\ndef extract_features(audio_signal, sr=22050, n_mfcc=13):\n    #print(\"Extracting features...\")\n    mfccs = librosa.feature.mfcc(y=audio_signal, sr=sr, n_mfcc=n_mfcc)\n    #print(f\"Extracted MFCCs shape: {mfccs.shape}\")\n    return mfccs.T\n\n# Process all audio files in a directory to extract features\ndef process_audio_files(directory):\n    all_features = []\n    print(f\"Extracting mfcc of all audio in {directory}\")\n    for filename in os.listdir(directory):\n        if filename.endswith('.wav'):\n            file_path = os.path.join(directory, filename)\n            #print(f\"Processing file: {file_path}\")\n            audio_signal, sr = librosa.load(file_path, sr=22050)\n            #print(f\"Loaded audio file with sample rate: {sr}\")\n            features = extract_features(audio_signal, sr)\n            all_features.append(features)\n    all_features = np.vstack(all_features)\n    print(f\"Extracted mfcc of all audio {directory}\")\n    print(f\"Combined features shape: {all_features.shape}\")\n    return all_features\n\n# Train a Universal Background Model (UBM)\ndef train_ubm(features, n_components=512):\n    print(\"Training UBM...\")\n    gmm = GaussianMixture(n_components=n_components, covariance_type='diag')\n    gmm.fit(features)\n    print(\"UBM trained.\")\n    return gmm\n\n# Train a total variability matrix (T-matrix)\ndef train_t_matrix(features, n_factors=13):\n    print(\"Training T-matrix...\")\n    pca = PCA(n_components=n_factors)\n    pca.fit(features)\n    print(\"T-matrix trained.\")\n    return pca\n\n# Extract i-vectors\ndef extract_i_vectors(features, ubm, t_matrix):\n    print(\"Extracting i-vectors...\")\n    posteriors = ubm.predict_proba(features)\n    i_vectors = np.dot(posteriors, t_matrix.components_)\n    print(f\"Extracted i-vectors shape: {i_vectors.shape}\")\n    return i_vectors\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:33:17.368091Z","iopub.execute_input":"2024-09-18T07:33:17.368855Z","iopub.status.idle":"2024-09-18T07:33:17.388747Z","shell.execute_reply.started":"2024-09-18T07:33:17.368796Z","shell.execute_reply":"2024-09-18T07:33:17.387020Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Directory containing the large universal dataset for training\nuniversal_dataset_directory = '/kaggle/input/mic-dev-eval/mic'\n\n# Process the universal dataset and extract features\nprint(\"Processing universal dataset...\")\nuniversal_features = process_audio_files(universal_dataset_directory)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:08:40.564036Z","iopub.execute_input":"2024-09-18T07:08:40.565584Z","iopub.status.idle":"2024-09-18T07:10:27.609484Z","shell.execute_reply.started":"2024-09-18T07:08:40.565505Z","shell.execute_reply":"2024-09-18T07:10:27.607050Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Processing universal dataset...\nExtracting mfcc of all audio in /kaggle/input/mic-dev-eval/mic\nExtracted mfcc of all audio /kaggle/input/mic-dev-eval/mic\nCombined features shape: (584029, 13)\n","output_type":"stream"}]},{"cell_type":"code","source":"ubm_model_path = 'ubm_model.joblib'\nt_matrix_path = 't_matrix.joblib'\n\n# Train UBM and T-matrix on the universal dataset\nif os.path.exists(ubm_model_path):\n    print(\"Loading UBM model from file...\")\n    ubm = joblib.load(ubm_model_path)\nelse:\n    ubm = train_ubm(universal_features)\n    joblib.dump(ubm, ubm_model_path)\n    print(f\"UBM model saved to {ubm_model_path}\")\n\n# Load or train T-matrix\nif os.path.exists(t_matrix_path):\n    print(\"Loading T-matrix from file...\")\n    t_matrix = joblib.load(t_matrix_path)\nelse:\n    t_matrix = train_t_matrix(universal_features)\n    joblib.dump(t_matrix, t_matrix_path)\n    print(f\"T-matrix saved to {t_matrix_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:33:22.880749Z","iopub.execute_input":"2024-09-18T07:33:22.881304Z","iopub.status.idle":"2024-09-18T07:33:23.119194Z","shell.execute_reply.started":"2024-09-18T07:33:22.881258Z","shell.execute_reply":"2024-09-18T07:33:23.117973Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Loading UBM model from file...\nTraining T-matrix...\nT-matrix trained.\nT-matrix saved to t_matrix.joblib\n","output_type":"stream"}]},{"cell_type":"code","source":"# Directory containing individual audio files\nindividual_files_directory = '/kaggle/input/tut-2016/TUT_2016/TUT_Acoustic_scenes_evaluation_all_in_one'\n\n# Process each individual audio file and extract its i-vector\nfor filename in os.listdir(individual_files_directory):\n    if filename.endswith('.wav'):\n        file_path = os.path.join(individual_files_directory, filename)\n        print(f\"\\nProcessing individual file: {file_path}\")\n        audio_signal, sr = librosa.load(file_path, sr=22050)\n        print(f\"Loaded audio file with sample rate: {sr}\")\n        features = extract_features(audio_signal, sr)\n        \n        # Extract i-vector for the current file using the pre-trained UBM and T-matrix\n        i_vector = extract_i_vectors(features, ubm, t_matrix)\n        \n        print(f'i-vector for {filename}: {i_vector}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-18T07:33:36.802143Z","iopub.execute_input":"2024-09-18T07:33:36.802653Z","iopub.status.idle":"2024-09-18T07:33:37.203793Z","shell.execute_reply.started":"2024-09-18T07:33:36.802578Z","shell.execute_reply":"2024-09-18T07:33:37.201665Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\nProcessing individual file: /kaggle/input/tut-2016/TUT_2016/TUT_Acoustic_scenes_evaluation_all_in_one/212_class7.wav\nLoaded audio file with sample rate: 22050\nExtracting i-vectors...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m features \u001b[38;5;241m=\u001b[39m extract_features(audio_signal, sr)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Extract i-vector for the current file using the pre-trained UBM and T-matrix\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m i_vector \u001b[38;5;241m=\u001b[39m \u001b[43mextract_i_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mubm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi-vector for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_vector\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[33], line 45\u001b[0m, in \u001b[0;36mextract_i_vectors\u001b[0;34m(features, ubm, t_matrix)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting i-vectors...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m posteriors \u001b[38;5;241m=\u001b[39m ubm\u001b[38;5;241m.\u001b[39mpredict_proba(features)\n\u001b[0;32m---> 45\u001b[0m i_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposteriors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted i-vectors shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_vectors\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m i_vectors\n","\u001b[0;31mValueError\u001b[0m: shapes (1292,512) and (13,13) not aligned: 512 (dim 1) != 13 (dim 0)"],"ename":"ValueError","evalue":"shapes (1292,512) and (13,13) not aligned: 512 (dim 1) != 13 (dim 0)","output_type":"error"}]}]}